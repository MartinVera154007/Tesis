{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kfolds augmented.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1r3WHyOxDtg3Mx_eBfvT6Ia6zAxypQvGD","authorship_tag":"ABX9TyN+HoCP80MKEr7ebFNdyNQ7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"P3rJLs6DLn8E"},"source":["!unzip /content/drive/MyDrive/ava.zip -d /content/ava1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jq9h0TGIPmDK","executionInfo":{"status":"ok","timestamp":1619805015791,"user_tz":360,"elapsed":3865,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}}},"source":["!mv /content/ava1/content/ava1/valid/complementary_colors/* /content/ava1/content/ava1/train/complementary_colors\n","!mv /content/ava1/content/ava1/valid/dutones/* /content/ava1/content/ava1/train/dutones\n","!mv /content/ava1/content/ava1/valid/hdr/* /content/ava1/content/ava1/train/hdr\n","!mv /content/ava1/content/ava1/valid/image_grain/* /content/ava1/content/ava1/train/image_grain\n","!mv /content/ava1/content/ava1/valid/light_on_white/* /content/ava1/content/ava1/train/light_on_white\n","!mv /content/ava1/content/ava1/valid/long_exposure/* /content/ava1/content/ava1/train/long_exposure\n","!mv /content/ava1/content/ava1/valid/macro/* /content/ava1/content/ava1/train/macro\n","!mv /content/ava1/content/ava1/valid/motion_blur/* /content/ava1/content/ava1/train/motion_blur\n","!mv /content/ava1/content/ava1/valid/negative_image/* /content/ava1/content/ava1/train/negative_image\n","!mv /content/ava1/content/ava1/valid/rule_of_thirds/* /content/ava1/content/ava1/train/rule_of_thirds\n","!mv /content/ava1/content/ava1/valid/shallow_dof/* /content/ava1/content/ava1/train/shallow_dof\n","!mv /content/ava1/content/ava1/valid/silhouttes/* /content/ava1/content/ava1/train/silhouttes\n","!mv /content/ava1/content/ava1/valid/soft_focus/* /content/ava1/content/ava1/train/soft_focus\n","!mv /content/ava1/content/ava1/valid/vanishing_point/* /content/ava1/content/ava1/train/vanishing_point\n","\n","!mv /content/ava1/content/ava1/test/complementary_colors/* /content/ava1/content/ava1/train/complementary_colors\n","!mv /content/ava1/content/ava1/test/dutones/* /content/ava1/content/ava1/train/dutones\n","!mv /content/ava1/content/ava1/test/hdr/* /content/ava1/content/ava1/train/hdr\n","!mv /content/ava1/content/ava1/test/image_grain/* /content/ava1/content/ava1/train/image_grain\n","!mv /content/ava1/content/ava1/test/light_on_white/* /content/ava1/content/ava1/train/light_on_white\n","!mv /content/ava1/content/ava1/test/long_exposure/* /content/ava1/content/ava1/train/long_exposure\n","!mv /content/ava1/content/ava1/test/macro/* /content/ava1/content/ava1/train/macro\n","!mv /content/ava1/content/ava1/test/motion_blur/* /content/ava1/content/ava1/train/motion_blur\n","!mv /content/ava1/content/ava1/test/negative_image/* /content/ava1/content/ava1/train/negative_image\n","!mv /content/ava1/content/ava1/test/rule_of_thirds/* /content/ava1/content/ava1/train/rule_of_thirds\n","!mv /content/ava1/content/ava1/test/shallow_dof/* /content/ava1/content/ava1/train/shallow_dof\n","!mv /content/ava1/content/ava1/test/silhouttes/* /content/ava1/content/ava1/train/silhouttes\n","!mv /content/ava1/content/ava1/test/soft_focus/* /content/ava1/content/ava1/train/soft_focus\n","!mv /content/ava1/content/ava1/test/vanishing_point/* /content/ava1/content/ava1/train/vanishing_point"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMUf5D-ZLL42","executionInfo":{"status":"ok","timestamp":1619805175791,"user_tz":360,"elapsed":529,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}}},"source":["import numpy as np \n","from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix, average_precision_score\n","from sklearn.preprocessing import label_binarize\n","from sklearn.model_selection import StratifiedKFold\n","from PIL import Image\n","import random\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.compat.v1 import ConfigProto\n","from tensorflow.compat.v1 import InteractiveSession\n","import warnings\n","import os\n","import shutil\n","import cv2\n","from PIL import ImageFile\n","warnings.simplefilter('error', Image.DecompressionBombWarning)\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","from PIL import Image\n","Image.MAX_IMAGE_PIXELS = 1000000000"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ntHdbjCKMF0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619805176132,"user_tz":360,"elapsed":864,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}},"outputId":"a1dd9400-d9d3-4474-d4ae-eaeb95ddc772"},"source":["### CONFIG ###\n","config = ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","\n","datasetFolderName='/content/ava1/content/ava1'\n","MODEL_FILENAME=\"model_cv.h5\"\n","sourceFiles=[]\n","classLabels= [\n","              'complementary_colors', \n","              'dutones', \n","              'hdr', \n","              'image_grain', \n","              'light_on_white', \n","              'long_exposure', \n","              'macro', \n","              'motion_blur', \n","              'negative_image', \n","              'rule_of_thirds',\n","              'shallow_dof',\n","              'silhouttes',\n","              'soft_focus',\n","              'vanishing_point'\n","]\n","batch_size = 16\n","epoch = 10"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py:1761: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8EU4tnUeMR6_","executionInfo":{"status":"ok","timestamp":1619805176132,"user_tz":360,"elapsed":861,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}}},"source":["def transferBetweenFolders(source, dest, splitRate):   \n","    global sourceFiles\n","    sourceFiles=os.listdir(source)\n","    if(len(sourceFiles)!=0):\n","        transferFileNumbers=int(len(sourceFiles)*splitRate)\n","        transferIndex=random.sample(range(0, len(sourceFiles)), transferFileNumbers)\n","        for eachIndex in transferIndex:\n","            shutil.move(source+str(sourceFiles[eachIndex]), dest+str(sourceFiles[eachIndex]))\n","    else:\n","        print(\"No file moved. Source empty!\")\n","\n","def transferAllClassBetweenFolders(source, dest, splitRate):\n","    for label in classLabels:\n","        transferBetweenFolders(datasetFolderName+'/'+source+'/'+label+'/', \n","                               datasetFolderName+'/'+dest+'/'+label+'/', \n","                               splitRate)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"RdJNRGHFMiVh","executionInfo":{"status":"ok","timestamp":1619805176133,"user_tz":360,"elapsed":860,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}}},"source":["### Lists to save images(X) and labels(Y)\n","X=[]\n","Y=[]"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVcsJMgYMomR","executionInfo":{"status":"ok","timestamp":1619805176134,"user_tz":360,"elapsed":858,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}}},"source":["def prepareNameWithLabels(folderName):\n","    sourceFiles=os.listdir(datasetFolderName+'/train/'+folderName)\n","    for val in sourceFiles:\n","        X.append(val)\n","        if (folderName==classLabels[0]):\n","            Y.append(0)\n","        elif (folderName==classLabels[1]):\n","            Y.append(1)\n","        elif (folderName==classLabels[2]):\n","            Y.append(2)\n","        elif (folderName==classLabels[3]):\n","            Y.append(3)\n","        elif (folderName==classLabels[4]):\n","            Y.append(4)\n","        elif (folderName==classLabels[5]):\n","            Y.append(5)\n","        elif (folderName==classLabels[6]):\n","            Y.append(6)\n","        elif (folderName==classLabels[7]):\n","            Y.append(7)\n","        elif (folderName==classLabels[8]):\n","            Y.append(8)\n","        elif (folderName==classLabels[9]):\n","            Y.append(9)\n","        elif (folderName==classLabels[10]):\n","            Y.append(10)\n","        elif (folderName==classLabels[11]):\n","            Y.append(11)\n","        elif (folderName==classLabels[12]):\n","            Y.append(12)\n","        elif (folderName==classLabels[13]):\n","            Y.append(13)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"0TvJRhoEMvWF","executionInfo":{"status":"ok","timestamp":1619805176134,"user_tz":360,"elapsed":855,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}}},"source":["# Organize file names and class labels in X and Y variables\n","prepareNameWithLabels(classLabels[0])\n","prepareNameWithLabels(classLabels[1])\n","prepareNameWithLabels(classLabels[2])       \n","prepareNameWithLabels(classLabels[3])       \n","prepareNameWithLabels(classLabels[4])       \n","prepareNameWithLabels(classLabels[5])       \n","prepareNameWithLabels(classLabels[6])       \n","prepareNameWithLabels(classLabels[7])       \n","prepareNameWithLabels(classLabels[8])       \n","prepareNameWithLabels(classLabels[9])       \n","prepareNameWithLabels(classLabels[10])       \n","prepareNameWithLabels(classLabels[11])       \n","prepareNameWithLabels(classLabels[12])       \n","prepareNameWithLabels(classLabels[13])       \n","\n","X=np.asarray(X)\n","Y=np.asarray(Y)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"DwvelH9dM0ri","executionInfo":{"status":"ok","timestamp":1619805176134,"user_tz":360,"elapsed":853,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}}},"source":["def getModel():\n","  densenet_model = tf.keras.applications.DenseNet201(include_top=False, input_shape=(256,256,3), weights='imagenet')\n","  model = Sequential()\n","  model.add(densenet_model)\n","  model.add(Flatten())\n","  model.add(Dropout(0.4))\n","  model.add(Dense(units=264, activation='relu'))\n","  model.add(Dropout(0.4))\n","  model.add(Dense(units=264, activation='relu'))\n","  model.add(Dropout(0.4))\n","  model.add(Dense(units=14, activation='softmax'))\n","\n","  model.compile(optimizer=Adam(learning_rate=0.0000065), loss='categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.AUC(curve='PR', multi_label=True)])\n","  \n","  return model"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"GtRDpMmlNm9U","executionInfo":{"status":"ok","timestamp":1619805176135,"user_tz":360,"elapsed":852,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}}},"source":["### Get mean average precision from predictions ###\n","def my_metrics(y_true, predictions):\n","    y_true_classes = label_binarize(y_true, [0,1,2,3,4,5,6,7,8,9,10,11,12,13])\n","    mAP = average_precision_score(y_true_classes, predictions)\n","    print(\"Mean Average Precision: {}\".format(mAP))"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mikjB43RMfr","executionInfo":{"status":"ok","timestamp":1619805176135,"user_tz":360,"elapsed":849,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}}},"source":["def augment_images(folder_name, folder_type):\n","  style_list = os.listdir(folder_name)\n","  style_list.sort()\n","  for style in style_list:\n","    style_folder = datasetFolderName + '/' + folder_type + '/' + style\n","    image_list = os.listdir(style_folder)\n","    for image in image_list:\n","      img = cv2.imread(datasetFolderName + '/' + folder_type + '/' + style + '/' + image)\n","      horizontal_flipped_image = cv2.flip(img, 1)\n","      vertical_flipped_image = cv2.flip(img, 0)\n","      cv2.imwrite(datasetFolderName + '/' + folder_type + '/' + style + '/h_' + image, horizontal_flipped_image)\n","      cv2.imwrite(datasetFolderName + '/' + folder_type + '/' + style + '/v_' + image, vertical_flipped_image)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"CR0FFQ91YGbD","executionInfo":{"status":"ok","timestamp":1619805176136,"user_tz":360,"elapsed":848,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}}},"source":["import glob\n","def delete_agumented_data(folder_name, folder_type):\n","  style_list = os.listdir(folder_name)\n","  style_list.sort()\n","  for style in style_list:\n","    style_folder = datasetFolderName + '/' + folder_type + '/' + style\n","    for f in glob.glob(style_folder + '/' + \"[h,v]*.jpg\"):\n","      os.remove(f)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"309SiwGINnnt","executionInfo":{"status":"ok","timestamp":1619854304317,"user_tz":360,"elapsed":49129025,"user":{"displayName":"Andre Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVpHUysNDbqOzxWpH-SewzdTGdlK2cx8F0jSvG0g=s64","userId":"13048267492628113316"}},"outputId":"d89003d9-985b-4f9f-d2c1-e9af735d44aa"},"source":["# Image dimensions\n","img_rows, img_cols =  256, 256\n","\n","# Data paths\n","train_path=datasetFolderName+'/train/'\n","validation_path=datasetFolderName+'/valid/'\n","test_path=datasetFolderName+'/test/'\n","\n","### Stratified K-Fold ###\n","skf = StratifiedKFold(n_splits=10, shuffle=True)\n","skf.get_n_splits(X, Y)\n","foldNum=0\n","for train_index, val_index in skf.split(X, Y):\n","    model=getModel()\n","    # Cut all images from validation to train (if any exists)\n","    transferAllClassBetweenFolders('valid', 'train', 1.0)\n","    delete_agumented_data(train_path, 'train')\n","    foldNum+=1\n","    print(\"Results for fold\",foldNum)\n","    X_train, X_val = X[train_index], X[val_index]\n","    Y_train, Y_val = Y[train_index], Y[val_index]\n","    # Move validation images of this fold from train folder to the validation folder\n","    for eachIndex in range(len(X_val)):\n","        classLabel=''\n","        if (Y_val[eachIndex]==0):\n","            classLabel=classLabels[0]\n","        elif (Y_val[eachIndex]==1):\n","            classLabel=classLabels[1]\n","        elif (Y_val[eachIndex]==2):\n","            classLabel=classLabels[2]\n","        elif (Y_val[eachIndex]==3):\n","            classLabel=classLabels[3]\n","        elif (Y_val[eachIndex]==4):\n","            classLabel=classLabels[4]\n","        elif (Y_val[eachIndex]==5):\n","            classLabel=classLabels[5]\n","        elif (Y_val[eachIndex]==6):\n","            classLabel=classLabels[6]\n","        elif (Y_val[eachIndex]==7):\n","            classLabel=classLabels[7]\n","        elif (Y_val[eachIndex]==8):\n","            classLabel=classLabels[8]\n","        elif (Y_val[eachIndex]==9):\n","            classLabel=classLabels[9]\n","        elif (Y_val[eachIndex]==10):\n","            classLabel=classLabels[10]\n","        elif (Y_val[eachIndex]==11):\n","            classLabel=classLabels[11]\n","        elif (Y_val[eachIndex]==12):\n","            classLabel=classLabels[12]\n","        elif (Y_val[eachIndex]==13):\n","            classLabel=classLabels[13]\n","\n","  \n","        # Copy the validation images to the validation folder\n","        shutil.move(datasetFolderName+'/train/'+classLabel+'/'+X_val[eachIndex], \n","                    datasetFolderName+'/valid/'+classLabel+'/'+X_val[eachIndex])\n","    \n","    augment_images(train_path, 'train')\n","    augment_images(validation_path, 'valid')\n","    train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n","    validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n","    test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n","        \n","    # Generate the batches\n","    train_generator = train_datagen.flow_from_directory(\n","        train_path,\n","        target_size=(img_rows, img_cols),\n","        batch_size=batch_size,\n","        class_mode='categorical',\n","        subset='training')\n","\n","    validation_generator = validation_datagen.flow_from_directory(\n","            validation_path,\n","            target_size=(img_rows, img_cols),\n","            batch_size=batch_size,\n","            class_mode='categorical',  # only data, no labels\n","            shuffle=False)   \n","   \n","    # Fit the model\n","    history=model.fit_generator(train_generator, \n","                        epochs=epoch, validation_data=validation_generator)\n","    \n","    predictions = model.predict_generator(validation_generator, verbose=1)\n","    yPredictions = np.argmax(predictions, axis=1)\n","    true_classes = validation_generator.classes\n","    \n","    # Evaluate the model\n","    print(\"\\n\\n***Performance on Validation data***\")    \n","    my_metrics(true_classes, predictions)\n","    print(\"\\n\\n\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","No file moved. Source empty!\n","Results for fold 1\n","Found 30381 images belonging to 14 classes.\n","Found 3378 images belonging to 14 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n"," 866/1899 [============>.................] - ETA: 3:59 - loss: 2.9383 - accuracy: 0.1048 - auc_1: 0.0822"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["1040/1899 [===============>..............] - ETA: 3:18 - loss: 2.8969 - accuracy: 0.1086 - auc_1: 0.0839"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"],"name":"stderr"},{"output_type":"stream","text":["1899/1899 [==============================] - 513s 248ms/step - loss: 2.7650 - accuracy: 0.1291 - auc_1: 0.0969 - val_loss: 2.0460 - val_accuracy: 0.3579 - val_auc_1: 0.3218\n","Epoch 2/10\n","1899/1899 [==============================] - 466s 245ms/step - loss: 2.1888 - accuracy: 0.2856 - auc_1: 0.2384 - val_loss: 1.6881 - val_accuracy: 0.4775 - val_auc_1: 0.4556\n","Epoch 3/10\n","1899/1899 [==============================] - 463s 244ms/step - loss: 1.9129 - accuracy: 0.3817 - auc_1: 0.3462 - val_loss: 1.5231 - val_accuracy: 0.5281 - val_auc_1: 0.5178\n","Epoch 4/10\n","1899/1899 [==============================] - 461s 243ms/step - loss: 1.6865 - accuracy: 0.4626 - auc_1: 0.4448 - val_loss: 1.4276 - val_accuracy: 0.5586 - val_auc_1: 0.5517\n","Epoch 5/10\n","1899/1899 [==============================] - 459s 241ms/step - loss: 1.5398 - accuracy: 0.5125 - auc_1: 0.5066 - val_loss: 1.3777 - val_accuracy: 0.5734 - val_auc_1: 0.5757\n","Epoch 6/10\n","1899/1899 [==============================] - 460s 242ms/step - loss: 1.3782 - accuracy: 0.5557 - auc_1: 0.5719 - val_loss: 1.3495 - val_accuracy: 0.5802 - val_auc_1: 0.5882\n","Epoch 7/10\n","1899/1899 [==============================] - 463s 244ms/step - loss: 1.2555 - accuracy: 0.5973 - auc_1: 0.6261 - val_loss: 1.3444 - val_accuracy: 0.5930 - val_auc_1: 0.5969\n","Epoch 8/10\n","1899/1899 [==============================] - 468s 246ms/step - loss: 1.1301 - accuracy: 0.6381 - auc_1: 0.6749 - val_loss: 1.3602 - val_accuracy: 0.5971 - val_auc_1: 0.6006\n","Epoch 9/10\n","1899/1899 [==============================] - 466s 245ms/step - loss: 1.0075 - accuracy: 0.6784 - auc_1: 0.7251 - val_loss: 1.4038 - val_accuracy: 0.5959 - val_auc_1: 0.5970\n","Epoch 10/10\n","1899/1899 [==============================] - 465s 245ms/step - loss: 0.8823 - accuracy: 0.7191 - auc_1: 0.7724 - val_loss: 1.4412 - val_accuracy: 0.5900 - val_auc_1: 0.5952\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["212/212 [==============================] - 33s 138ms/step\n","\n","\n","***Performance on Validation data***\n","Mean Average Precision: 0.6005549909221897\n","\n","\n","\n","Results for fold 2\n","Found 30381 images belonging to 14 classes.\n","Found 3378 images belonging to 14 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n"," 122/1899 [>.............................] - ETA: 6:50 - loss: 3.5788 - accuracy: 0.0838 - auc_2: 0.0783"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["1596/1899 [========================>.....] - ETA: 1:09 - loss: 2.8364 - accuracy: 0.1106 - auc_2: 0.0887"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"],"name":"stderr"},{"output_type":"stream","text":["1899/1899 [==============================] - 493s 248ms/step - loss: 2.7945 - accuracy: 0.1179 - auc_2: 0.0938 - val_loss: 2.0454 - val_accuracy: 0.3481 - val_auc_2: 0.3280\n","Epoch 2/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 2.1958 - accuracy: 0.2800 - auc_2: 0.2351 - val_loss: 1.6978 - val_accuracy: 0.4882 - val_auc_2: 0.4675\n","Epoch 3/10\n","1899/1899 [==============================] - 466s 246ms/step - loss: 1.9143 - accuracy: 0.3838 - auc_2: 0.3485 - val_loss: 1.4952 - val_accuracy: 0.5388 - val_auc_2: 0.5360\n","Epoch 4/10\n","1899/1899 [==============================] - 466s 245ms/step - loss: 1.6796 - accuracy: 0.4628 - auc_2: 0.4496 - val_loss: 1.3962 - val_accuracy: 0.5719 - val_auc_2: 0.5756\n","Epoch 5/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 1.5283 - accuracy: 0.5119 - auc_2: 0.5151 - val_loss: 1.3740 - val_accuracy: 0.5808 - val_auc_2: 0.5912\n","Epoch 6/10\n","1899/1899 [==============================] - 466s 246ms/step - loss: 1.3900 - accuracy: 0.5610 - auc_2: 0.5643 - val_loss: 1.3789 - val_accuracy: 0.5782 - val_auc_2: 0.5966\n","Epoch 7/10\n","1899/1899 [==============================] - 464s 245ms/step - loss: 1.2824 - accuracy: 0.5942 - auc_2: 0.6135 - val_loss: 1.3538 - val_accuracy: 0.5953 - val_auc_2: 0.6090\n","Epoch 8/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 1.1198 - accuracy: 0.6395 - auc_2: 0.6736 - val_loss: 1.3890 - val_accuracy: 0.5930 - val_auc_2: 0.6147\n","Epoch 9/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 0.9825 - accuracy: 0.6851 - auc_2: 0.7290 - val_loss: 1.4362 - val_accuracy: 0.5924 - val_auc_2: 0.6126\n","Epoch 10/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 0.8723 - accuracy: 0.7180 - auc_2: 0.7706 - val_loss: 1.5009 - val_accuracy: 0.5933 - val_auc_2: 0.6096\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["212/212 [==============================] - 32s 136ms/step\n","\n","\n","***Performance on Validation data***\n","Mean Average Precision: 0.6158236030934275\n","\n","\n","\n","Results for fold 3\n","Found 30381 images belonging to 14 classes.\n","Found 3378 images belonging to 14 classes.\n","Epoch 1/10\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":[" 172/1899 [=>............................] - ETA: 6:38 - loss: 3.6318 - accuracy: 0.0783 - auc_3: 0.0772"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"],"name":"stderr"},{"output_type":"stream","text":["1899/1899 [==============================] - ETA: 0s - loss: 2.8426 - accuracy: 0.1117 - auc_3: 0.0896"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1899/1899 [==============================] - 493s 247ms/step - loss: 2.8424 - accuracy: 0.1117 - auc_3: 0.0896 - val_loss: 2.0704 - val_accuracy: 0.3526 - val_auc_3: 0.3195\n","Epoch 2/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 2.2008 - accuracy: 0.2923 - auc_3: 0.2365 - val_loss: 1.7071 - val_accuracy: 0.4615 - val_auc_3: 0.4488\n","Epoch 3/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 1.9038 - accuracy: 0.3932 - auc_3: 0.3544 - val_loss: 1.5512 - val_accuracy: 0.5145 - val_auc_3: 0.5082\n","Epoch 4/10\n","1899/1899 [==============================] - 468s 246ms/step - loss: 1.6792 - accuracy: 0.4652 - auc_3: 0.4462 - val_loss: 1.4649 - val_accuracy: 0.5506 - val_auc_3: 0.5462\n","Epoch 5/10\n","1899/1899 [==============================] - 468s 247ms/step - loss: 1.5247 - accuracy: 0.5129 - auc_3: 0.5102 - val_loss: 1.4058 - val_accuracy: 0.5660 - val_auc_3: 0.5706\n","Epoch 6/10\n","1899/1899 [==============================] - 465s 245ms/step - loss: 1.3746 - accuracy: 0.5613 - auc_3: 0.5713 - val_loss: 1.3919 - val_accuracy: 0.5743 - val_auc_3: 0.5871\n","Epoch 7/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 1.2299 - accuracy: 0.6066 - auc_3: 0.6281 - val_loss: 1.4181 - val_accuracy: 0.5675 - val_auc_3: 0.5852\n","Epoch 8/10\n","1899/1899 [==============================] - 468s 246ms/step - loss: 1.1277 - accuracy: 0.6448 - auc_3: 0.6696 - val_loss: 1.4292 - val_accuracy: 0.5864 - val_auc_3: 0.5880\n","Epoch 9/10\n","1899/1899 [==============================] - 469s 247ms/step - loss: 0.9801 - accuracy: 0.6854 - auc_3: 0.7260 - val_loss: 1.4786 - val_accuracy: 0.5829 - val_auc_3: 0.5856\n","Epoch 10/10\n","1899/1899 [==============================] - 468s 246ms/step - loss: 0.8889 - accuracy: 0.7161 - auc_3: 0.7600 - val_loss: 1.5141 - val_accuracy: 0.5861 - val_auc_3: 0.5912\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["212/212 [==============================] - 32s 134ms/step\n","\n","\n","***Performance on Validation data***\n","Mean Average Precision: 0.5983569942927803\n","\n","\n","\n","Results for fold 4\n","Found 30384 images belonging to 14 classes.\n","Found 3375 images belonging to 14 classes.\n","Epoch 1/10\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":[" 420/1899 [=====>........................] - ETA: 5:43 - loss: 3.1199 - accuracy: 0.0944 - auc_4: 0.0785"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["1824/1899 [===========================>..] - ETA: 17s - loss: 2.7667 - accuracy: 0.1279 - auc_4: 0.0985"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"],"name":"stderr"},{"output_type":"stream","text":["1899/1899 [==============================] - 496s 249ms/step - loss: 2.7571 - accuracy: 0.1298 - auc_4: 0.0999 - val_loss: 2.0142 - val_accuracy: 0.3627 - val_auc_4: 0.3330\n","Epoch 2/10\n","1899/1899 [==============================] - 464s 244ms/step - loss: 2.1536 - accuracy: 0.2927 - auc_4: 0.2433 - val_loss: 1.6853 - val_accuracy: 0.4921 - val_auc_4: 0.4620\n","Epoch 3/10\n","1899/1899 [==============================] - 466s 246ms/step - loss: 1.8441 - accuracy: 0.4021 - auc_4: 0.3645 - val_loss: 1.5177 - val_accuracy: 0.5499 - val_auc_4: 0.5228\n","Epoch 4/10\n","1899/1899 [==============================] - 468s 247ms/step - loss: 1.6773 - accuracy: 0.4612 - auc_4: 0.4389 - val_loss: 1.4285 - val_accuracy: 0.5665 - val_auc_4: 0.5611\n","Epoch 5/10\n","1899/1899 [==============================] - 468s 246ms/step - loss: 1.5272 - accuracy: 0.5107 - auc_4: 0.5084 - val_loss: 1.4039 - val_accuracy: 0.5911 - val_auc_4: 0.5825\n","Epoch 6/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 1.3447 - accuracy: 0.5632 - auc_4: 0.5772 - val_loss: 1.3751 - val_accuracy: 0.5914 - val_auc_4: 0.5990\n","Epoch 7/10\n","1899/1899 [==============================] - 466s 246ms/step - loss: 1.2400 - accuracy: 0.6001 - auc_4: 0.6230 - val_loss: 1.3648 - val_accuracy: 0.5917 - val_auc_4: 0.6083\n","Epoch 8/10\n","1899/1899 [==============================] - 468s 246ms/step - loss: 1.1117 - accuracy: 0.6386 - auc_4: 0.6764 - val_loss: 1.3743 - val_accuracy: 0.6006 - val_auc_4: 0.6137\n","Epoch 9/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 0.9870 - accuracy: 0.6809 - auc_4: 0.7270 - val_loss: 1.4063 - val_accuracy: 0.6012 - val_auc_4: 0.6156\n","Epoch 10/10\n","1899/1899 [==============================] - 465s 245ms/step - loss: 0.8823 - accuracy: 0.7135 - auc_4: 0.7664 - val_loss: 1.4420 - val_accuracy: 0.5950 - val_auc_4: 0.6120\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["211/211 [==============================] - 33s 132ms/step\n","\n","\n","***Performance on Validation data***\n","Mean Average Precision: 0.6193038901739156\n","\n","\n","\n","Results for fold 5\n","Found 30384 images belonging to 14 classes.\n","Found 3375 images belonging to 14 classes.\n","Epoch 1/10\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["1251/1899 [==================>...........] - ETA: 2:30 - loss: 2.8799 - accuracy: 0.1076 - auc_5: 0.0854"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"],"name":"stderr"},{"output_type":"stream","text":["1535/1899 [=======================>......] - ETA: 1:24 - loss: 2.8335 - accuracy: 0.1144 - auc_5: 0.0894"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["1899/1899 [==============================] - 495s 248ms/step - loss: 2.7844 - accuracy: 0.1234 - auc_5: 0.0954 - val_loss: 2.0236 - val_accuracy: 0.3846 - val_auc_5: 0.3229\n","Epoch 2/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 2.1734 - accuracy: 0.2924 - auc_5: 0.2404 - val_loss: 1.6749 - val_accuracy: 0.4957 - val_auc_5: 0.4677\n","Epoch 3/10\n","1899/1899 [==============================] - 466s 246ms/step - loss: 1.8927 - accuracy: 0.3944 - auc_5: 0.3533 - val_loss: 1.5033 - val_accuracy: 0.5387 - val_auc_5: 0.5282\n","Epoch 4/10\n","1899/1899 [==============================] - 465s 245ms/step - loss: 1.6613 - accuracy: 0.4703 - auc_5: 0.4548 - val_loss: 1.4016 - val_accuracy: 0.5686 - val_auc_5: 0.5737\n","Epoch 5/10\n","1899/1899 [==============================] - 465s 245ms/step - loss: 1.5101 - accuracy: 0.5208 - auc_5: 0.5198 - val_loss: 1.3725 - val_accuracy: 0.5736 - val_auc_5: 0.5865\n","Epoch 6/10\n","1899/1899 [==============================] - 463s 244ms/step - loss: 1.3769 - accuracy: 0.5646 - auc_5: 0.5697 - val_loss: 1.3455 - val_accuracy: 0.5846 - val_auc_5: 0.5998\n","Epoch 7/10\n","1899/1899 [==============================] - 462s 243ms/step - loss: 1.2481 - accuracy: 0.6028 - auc_5: 0.6266 - val_loss: 1.3130 - val_accuracy: 0.5967 - val_auc_5: 0.6138\n","Epoch 8/10\n","1899/1899 [==============================] - 460s 242ms/step - loss: 1.1241 - accuracy: 0.6425 - auc_5: 0.6736 - val_loss: 1.3211 - val_accuracy: 0.5932 - val_auc_5: 0.6171\n","Epoch 9/10\n","1899/1899 [==============================] - 461s 243ms/step - loss: 1.0040 - accuracy: 0.6801 - auc_5: 0.7201 - val_loss: 1.3269 - val_accuracy: 0.5994 - val_auc_5: 0.6191\n","Epoch 10/10\n","1899/1899 [==============================] - 462s 243ms/step - loss: 0.8786 - accuracy: 0.7203 - auc_5: 0.7718 - val_loss: 1.3829 - val_accuracy: 0.6024 - val_auc_5: 0.6166\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["211/211 [==============================] - 31s 132ms/step\n","\n","\n","***Performance on Validation data***\n","Mean Average Precision: 0.6196939589112407\n","\n","\n","\n","Results for fold 6\n","Found 30384 images belonging to 14 classes.\n","Found 3375 images belonging to 14 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","1356/1899 [====================>.........] - ETA: 2:04 - loss: 2.8228 - accuracy: 0.1105 - auc_6: 0.0880"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["1899/1899 [==============================] - ETA: 0s - loss: 2.7468 - accuracy: 0.1250 - auc_6: 0.0974"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1899/1899 [==============================] - 489s 245ms/step - loss: 2.7467 - accuracy: 0.1250 - auc_6: 0.0975 - val_loss: 2.0103 - val_accuracy: 0.3674 - val_auc_6: 0.3320\n","Epoch 2/10\n","1899/1899 [==============================] - 458s 241ms/step - loss: 2.1495 - accuracy: 0.3008 - auc_6: 0.2445 - val_loss: 1.6993 - val_accuracy: 0.4776 - val_auc_6: 0.4571\n","Epoch 3/10\n","1899/1899 [==============================] - 454s 239ms/step - loss: 1.9041 - accuracy: 0.3846 - auc_6: 0.3427 - val_loss: 1.5530 - val_accuracy: 0.5170 - val_auc_6: 0.5211\n","Epoch 4/10\n","1899/1899 [==============================] - 451s 238ms/step - loss: 1.7060 - accuracy: 0.4529 - auc_6: 0.4317 - val_loss: 1.4683 - val_accuracy: 0.5399 - val_auc_6: 0.5590\n","Epoch 5/10\n","1899/1899 [==============================] - 450s 237ms/step - loss: 1.5359 - accuracy: 0.5148 - auc_6: 0.5010 - val_loss: 1.4156 - val_accuracy: 0.5582 - val_auc_6: 0.5800\n","Epoch 6/10\n","1899/1899 [==============================] - 449s 236ms/step - loss: 1.4020 - accuracy: 0.5571 - auc_6: 0.5573 - val_loss: 1.4039 - val_accuracy: 0.5695 - val_auc_6: 0.5928\n","Epoch 7/10\n","1899/1899 [==============================] - 451s 238ms/step - loss: 1.2709 - accuracy: 0.5988 - auc_6: 0.6086 - val_loss: 1.3940 - val_accuracy: 0.5689 - val_auc_6: 0.5996\n","Epoch 8/10\n","1899/1899 [==============================] - 450s 237ms/step - loss: 1.1283 - accuracy: 0.6403 - auc_6: 0.6707 - val_loss: 1.4203 - val_accuracy: 0.5781 - val_auc_6: 0.6047\n","Epoch 9/10\n","1899/1899 [==============================] - 451s 237ms/step - loss: 0.9998 - accuracy: 0.6770 - auc_6: 0.7177 - val_loss: 1.4404 - val_accuracy: 0.5858 - val_auc_6: 0.6014\n","Epoch 10/10\n","1899/1899 [==============================] - 451s 238ms/step - loss: 0.8933 - accuracy: 0.7114 - auc_6: 0.7590 - val_loss: 1.4904 - val_accuracy: 0.5739 - val_auc_6: 0.6004\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["211/211 [==============================] - 29s 121ms/step\n","\n","\n","***Performance on Validation data***\n","Mean Average Precision: 0.6069019585277242\n","\n","\n","\n","Results for fold 7\n","Found 30384 images belonging to 14 classes.\n","Found 3375 images belonging to 14 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","1509/1899 [======================>.......] - ETA: 1:27 - loss: 2.8008 - accuracy: 0.1166 - auc_7: 0.0878"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["1835/1899 [===========================>..] - ETA: 14s - loss: 2.7595 - accuracy: 0.1246 - auc_7: 0.0933"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"],"name":"stderr"},{"output_type":"stream","text":["1899/1899 [==============================] - 475s 239ms/step - loss: 2.7520 - accuracy: 0.1261 - auc_7: 0.0945 - val_loss: 2.0812 - val_accuracy: 0.3532 - val_auc_7: 0.3068\n","Epoch 2/10\n","1899/1899 [==============================] - 447s 236ms/step - loss: 2.1824 - accuracy: 0.2986 - auc_7: 0.2450 - val_loss: 1.8017 - val_accuracy: 0.4548 - val_auc_7: 0.4133\n","Epoch 3/10\n","1899/1899 [==============================] - 446s 235ms/step - loss: 1.8860 - accuracy: 0.3974 - auc_7: 0.3589 - val_loss: 1.6378 - val_accuracy: 0.4954 - val_auc_7: 0.4731\n","Epoch 4/10\n","1899/1899 [==============================] - 445s 235ms/step - loss: 1.6897 - accuracy: 0.4657 - auc_7: 0.4436 - val_loss: 1.5762 - val_accuracy: 0.5203 - val_auc_7: 0.5093\n","Epoch 5/10\n","1899/1899 [==============================] - 448s 236ms/step - loss: 1.5192 - accuracy: 0.5176 - auc_7: 0.5114 - val_loss: 1.5444 - val_accuracy: 0.5390 - val_auc_7: 0.5345\n","Epoch 6/10\n","1899/1899 [==============================] - 445s 235ms/step - loss: 1.3874 - accuracy: 0.5624 - auc_7: 0.5698 - val_loss: 1.5362 - val_accuracy: 0.5517 - val_auc_7: 0.5428\n","Epoch 7/10\n","1899/1899 [==============================] - 447s 235ms/step - loss: 1.2537 - accuracy: 0.6037 - auc_7: 0.6193 - val_loss: 1.5514 - val_accuracy: 0.5547 - val_auc_7: 0.5471\n","Epoch 8/10\n","1899/1899 [==============================] - 456s 240ms/step - loss: 1.1263 - accuracy: 0.6403 - auc_7: 0.6719 - val_loss: 1.5476 - val_accuracy: 0.5573 - val_auc_7: 0.5539\n","Epoch 9/10\n","1899/1899 [==============================] - 462s 243ms/step - loss: 1.0080 - accuracy: 0.6759 - auc_7: 0.7172 - val_loss: 1.6110 - val_accuracy: 0.5556 - val_auc_7: 0.5537\n","Epoch 10/10\n","1899/1899 [==============================] - 461s 243ms/step - loss: 0.8754 - accuracy: 0.7209 - auc_7: 0.7709 - val_loss: 1.6528 - val_accuracy: 0.5653 - val_auc_7: 0.5591\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["211/211 [==============================] - 31s 132ms/step\n","\n","\n","***Performance on Validation data***\n","Mean Average Precision: 0.5670253164203957\n","\n","\n","\n","Results for fold 8\n","Found 30384 images belonging to 14 classes.\n","Found 3375 images belonging to 14 classes.\n","Epoch 1/10\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":[" 760/1899 [===========>..................] - ETA: 4:21 - loss: 2.9673 - accuracy: 0.1046 - auc_8: 0.0816"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["1374/1899 [====================>.........] - ETA: 2:00 - loss: 2.8330 - accuracy: 0.1176 - auc_8: 0.0879"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"],"name":"stderr"},{"output_type":"stream","text":["1899/1899 [==============================] - 491s 246ms/step - loss: 2.7619 - accuracy: 0.1292 - auc_8: 0.0960 - val_loss: 2.0733 - val_accuracy: 0.3455 - val_auc_8: 0.3125\n","Epoch 2/10\n","1899/1899 [==============================] - 463s 244ms/step - loss: 2.1809 - accuracy: 0.2890 - auc_8: 0.2375 - val_loss: 1.7410 - val_accuracy: 0.4720 - val_auc_8: 0.4426\n","Epoch 3/10\n","1899/1899 [==============================] - 464s 244ms/step - loss: 1.8816 - accuracy: 0.3924 - auc_8: 0.3582 - val_loss: 1.5564 - val_accuracy: 0.5179 - val_auc_8: 0.5102\n","Epoch 4/10\n","1899/1899 [==============================] - 463s 244ms/step - loss: 1.6946 - accuracy: 0.4631 - auc_8: 0.4395 - val_loss: 1.4718 - val_accuracy: 0.5387 - val_auc_8: 0.5403\n","Epoch 5/10\n","1899/1899 [==============================] - 465s 245ms/step - loss: 1.5273 - accuracy: 0.5192 - auc_8: 0.5157 - val_loss: 1.4020 - val_accuracy: 0.5680 - val_auc_8: 0.5689\n","Epoch 6/10\n","1899/1899 [==============================] - 465s 245ms/step - loss: 1.3696 - accuracy: 0.5607 - auc_8: 0.5754 - val_loss: 1.3854 - val_accuracy: 0.5716 - val_auc_8: 0.5814\n","Epoch 7/10\n","1899/1899 [==============================] - 461s 243ms/step - loss: 1.2500 - accuracy: 0.6081 - auc_8: 0.6254 - val_loss: 1.3870 - val_accuracy: 0.5837 - val_auc_8: 0.5912\n","Epoch 8/10\n","1899/1899 [==============================] - 464s 244ms/step - loss: 1.1281 - accuracy: 0.6409 - auc_8: 0.6728 - val_loss: 1.4132 - val_accuracy: 0.5858 - val_auc_8: 0.5945\n","Epoch 9/10\n","1899/1899 [==============================] - 464s 244ms/step - loss: 1.0019 - accuracy: 0.6819 - auc_8: 0.7251 - val_loss: 1.4448 - val_accuracy: 0.5796 - val_auc_8: 0.5912\n","Epoch 10/10\n","1899/1899 [==============================] - 463s 244ms/step - loss: 0.8844 - accuracy: 0.7165 - auc_8: 0.7717 - val_loss: 1.4968 - val_accuracy: 0.5837 - val_auc_8: 0.5913\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["211/211 [==============================] - 33s 134ms/step\n","\n","\n","***Performance on Validation data***\n","Mean Average Precision: 0.5963214844898702\n","\n","\n","\n","Results for fold 9\n","Found 30384 images belonging to 14 classes.\n","Found 3375 images belonging to 14 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","  61/1899 [..............................] - ETA: 7:04 - loss: 3.7787 - accuracy: 0.0674 - auc_9: 0.0808"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"],"name":"stderr"},{"output_type":"stream","text":[" 705/1899 [==========>...................] - ETA: 4:35 - loss: 3.0108 - accuracy: 0.0936 - auc_9: 0.0805"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["1899/1899 [==============================] - 494s 248ms/step - loss: 2.7724 - accuracy: 0.1246 - auc_9: 0.0967 - val_loss: 2.0957 - val_accuracy: 0.3419 - val_auc_9: 0.3112\n","Epoch 2/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 2.2146 - accuracy: 0.2782 - auc_9: 0.2274 - val_loss: 1.7739 - val_accuracy: 0.4720 - val_auc_9: 0.4431\n","Epoch 3/10\n","1899/1899 [==============================] - 467s 246ms/step - loss: 1.9316 - accuracy: 0.3757 - auc_9: 0.3364 - val_loss: 1.5741 - val_accuracy: 0.5256 - val_auc_9: 0.5041\n","Epoch 4/10\n","1899/1899 [==============================] - 466s 246ms/step - loss: 1.7117 - accuracy: 0.4583 - auc_9: 0.4353 - val_loss: 1.4979 - val_accuracy: 0.5399 - val_auc_9: 0.5352\n","Epoch 5/10\n","1899/1899 [==============================] - 464s 244ms/step - loss: 1.5267 - accuracy: 0.5169 - auc_9: 0.5138 - val_loss: 1.4686 - val_accuracy: 0.5526 - val_auc_9: 0.5465\n","Epoch 6/10\n","1899/1899 [==============================] - 464s 244ms/step - loss: 1.3897 - accuracy: 0.5566 - auc_9: 0.5702 - val_loss: 1.4432 - val_accuracy: 0.5650 - val_auc_9: 0.5611\n","Epoch 7/10\n","1899/1899 [==============================] - 464s 244ms/step - loss: 1.2611 - accuracy: 0.5986 - auc_9: 0.6232 - val_loss: 1.4550 - val_accuracy: 0.5656 - val_auc_9: 0.5705\n","Epoch 8/10\n","1899/1899 [==============================] - 464s 244ms/step - loss: 1.1254 - accuracy: 0.6432 - auc_9: 0.6783 - val_loss: 1.4957 - val_accuracy: 0.5680 - val_auc_9: 0.5752\n","Epoch 9/10\n","1899/1899 [==============================] - 462s 243ms/step - loss: 1.0031 - accuracy: 0.6767 - auc_9: 0.7213 - val_loss: 1.5101 - val_accuracy: 0.5772 - val_auc_9: 0.5806\n","Epoch 10/10\n","1899/1899 [==============================] - 464s 244ms/step - loss: 0.8694 - accuracy: 0.7209 - auc_9: 0.7774 - val_loss: 1.5557 - val_accuracy: 0.5727 - val_auc_9: 0.5804\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["211/211 [==============================] - 32s 135ms/step\n","\n","\n","***Performance on Validation data***\n","Mean Average Precision: 0.5822602001493061\n","\n","\n","\n","Results for fold 10\n","Found 30384 images belonging to 14 classes.\n","Found 3375 images belonging to 14 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","  39/1899 [..............................] - ETA: 7:00 - loss: 3.7482 - accuracy: 0.0743 - auc_10: 0.0853"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["1203/1899 [==================>...........] - ETA: 2:38 - loss: 2.8877 - accuracy: 0.1053 - auc_10: 0.0847"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"],"name":"stderr"},{"output_type":"stream","text":["1899/1899 [==============================] - 489s 245ms/step - loss: 2.7847 - accuracy: 0.1228 - auc_10: 0.0959 - val_loss: 2.0154 - val_accuracy: 0.3748 - val_auc_10: 0.3318\n","Epoch 2/10\n","1899/1899 [==============================] - 462s 243ms/step - loss: 2.1693 - accuracy: 0.3006 - auc_10: 0.2440 - val_loss: 1.6978 - val_accuracy: 0.4744 - val_auc_10: 0.4514\n","Epoch 3/10\n","1899/1899 [==============================] - 463s 244ms/step - loss: 1.8992 - accuracy: 0.3939 - auc_10: 0.3520 - val_loss: 1.5074 - val_accuracy: 0.5212 - val_auc_10: 0.5193\n","Epoch 4/10\n","1899/1899 [==============================] - 463s 244ms/step - loss: 1.6889 - accuracy: 0.4597 - auc_10: 0.4371 - val_loss: 1.4420 - val_accuracy: 0.5487 - val_auc_10: 0.5537\n","Epoch 5/10\n","1899/1899 [==============================] - 462s 243ms/step - loss: 1.5369 - accuracy: 0.5125 - auc_10: 0.5053 - val_loss: 1.4026 - val_accuracy: 0.5641 - val_auc_10: 0.5741\n","Epoch 6/10\n","1899/1899 [==============================] - 461s 243ms/step - loss: 1.3904 - accuracy: 0.5595 - auc_10: 0.5665 - val_loss: 1.3804 - val_accuracy: 0.5745 - val_auc_10: 0.5844\n","Epoch 7/10\n","1899/1899 [==============================] - 462s 243ms/step - loss: 1.2639 - accuracy: 0.5966 - auc_10: 0.6175 - val_loss: 1.4038 - val_accuracy: 0.5769 - val_auc_10: 0.5906\n","Epoch 8/10\n","1899/1899 [==============================] - 455s 240ms/step - loss: 1.1145 - accuracy: 0.6421 - auc_10: 0.6784 - val_loss: 1.3983 - val_accuracy: 0.5819 - val_auc_10: 0.5946\n","Epoch 9/10\n","1899/1899 [==============================] - 450s 237ms/step - loss: 1.0147 - accuracy: 0.6715 - auc_10: 0.7144 - val_loss: 1.4384 - val_accuracy: 0.5870 - val_auc_10: 0.5922\n","Epoch 10/10\n","1899/1899 [==============================] - 447s 235ms/step - loss: 0.8949 - accuracy: 0.7126 - auc_10: 0.7612 - val_loss: 1.4753 - val_accuracy: 0.5840 - val_auc_10: 0.5963\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["211/211 [==============================] - 29s 121ms/step\n","\n","\n","***Performance on Validation data***\n","Mean Average Precision: 0.6046347440183439\n","\n","\n","\n"],"name":"stdout"}]}]}